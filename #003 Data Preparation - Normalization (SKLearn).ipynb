{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Data Preparation - Normalization (SKLearn).ipynb","provenance":[],"authorship_tag":"ABX9TyN96T5sygLZgprBTKuQKwt2"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"e9xeYk3Qxtvv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":104},"executionInfo":{"status":"ok","timestamp":1593345534269,"user_tz":-420,"elapsed":4398,"user":{"displayName":"Dwi Wahyu Effendi","photoUrl":"","userId":"05203034688020358716"}},"outputId":"193a5376-bd2a-45e7-9173-0ce6f8f68c66"},"source":["from sklearn.preprocessing import MinMaxScaler\n","data =[[12000000, 33], [35000000, 45], [4000000, 23], [6500000, 26], [9000000, 29]]\n","scaler = MinMaxScaler()\n","scaler.fit(data)\n","print(scaler.transform(data))"],"execution_count":2,"outputs":[{"output_type":"stream","text":["[[0.25806452 0.45454545]\n"," [1.         1.        ]\n"," [0.         0.        ]\n"," [0.08064516 0.13636364]\n"," [0.16129032 0.27272727]]\n"],"name":"stdout"}]}]}